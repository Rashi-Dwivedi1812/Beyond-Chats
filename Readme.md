# ğŸš€ BeyondChats â€“ Full Stack Automation Assignment

**Role Applied:** Full Stack Developer Intern  
**Tech Focus:** Web Scraping â€¢ Backend APIs â€¢ Automation â€¢ AI Integration â€¢ React UI

---

## ğŸ‘‹ Overview (For Recruiters)

This project is a **production-style full stack automation system** built as part of a Full Stack Development internship assignment.

It demonstrates my ability to:
- Design clean backend APIs
- Scrape and process real-world web data
- Build reliable automation pipelines
- Integrate AI services responsibly (with fallbacks)
- Present data clearly using a modern React UI

The system **scrapes original blog articles**, enhances them using **external references and AI**, and displays **both original and updated versions** without overwriting data.

---

## ğŸ§  What This Project Does (High-Level)

1. Scrapes original blog articles from **BeyondChats**
2. Stores them in **MongoDB**
3. Searches Google for related high-ranking articles
4. Scrapes content from external sources
5. Uses an LLM to enhance the original article
6. Publishes a **new AI-updated article**
7. Displays both versions in a **React frontend**

---

## âœ… Key Engineering Highlights

- ğŸ” **Web Scraping:** Axios + Cheerio
- ğŸ§© **REST APIs:** Node.js, Express, MongoDB
- ğŸ”„ **Automation Pipeline:** Robust, error-tolerant design
- ğŸ§  **AI Integration:** LLM-based rewriting with graceful fallback
- ğŸ§± **Data Integrity:** Originals are never overwritten
- ğŸ–¥ **Frontend:** Clean, responsive React UI
- ğŸ” **Security:** Environment variables, no secrets committed

---

## ğŸ—ï¸ Tech Stack

### Frontend
- React.js
- Tailwind CSS
- Axios

### Backend
- Node.js
- Express.js
- MongoDB
- Mongoose

### Automation / Scraping
- Axios
- Cheerio
- Google Search API
- OpenAI API (LLM)

---

## ğŸ“‚ Project Structure

# ğŸš€ BeyondChats â€“ Full Stack Automation Assignment

**Role Applied:** Full Stack Developer Intern  
**Tech Focus:** Web Scraping â€¢ Backend APIs â€¢ Automation â€¢ AI Integration â€¢ React UI

---

## ğŸ‘‹ Overview (For Recruiters)

This project is a **production-style full stack automation system** built as part of a Full Stack Development internship assignment.

It demonstrates my ability to:
- Design clean backend APIs
- Scrape and process real-world web data
- Build reliable automation pipelines
- Integrate AI services responsibly (with fallbacks)
- Present data clearly using a modern React UI

The system **scrapes original blog articles**, enhances them using **external references and AI**, and displays **both original and updated versions** without overwriting data.

---

## ğŸ§  What This Project Does (High-Level)

1. Scrapes original blog articles from **BeyondChats**
2. Stores them in **MongoDB**
3. Searches Google for related high-ranking articles
4. Scrapes content from external sources
5. Uses an LLM to enhance the original article
6. Publishes a **new AI-updated article**
7. Displays both versions in a **React frontend**

---

## âœ… Key Engineering Highlights

- ğŸ” **Web Scraping:** Axios + Cheerio
- ğŸ§© **REST APIs:** Node.js, Express, MongoDB
- ğŸ”„ **Automation Pipeline:** Robust, error-tolerant design
- ğŸ§  **AI Integration:** LLM-based rewriting with graceful fallback
- ğŸ§± **Data Integrity:** Originals are never overwritten
- ğŸ–¥ **Frontend:** Clean, responsive React UI
- ğŸ” **Security:** Environment variables, no secrets committed

---

## ğŸ—ï¸ Tech Stack

### Frontend
- React.js
- Tailwind CSS
- Axios

### Backend
- Node.js
- Express.js
- MongoDB
- Mongoose

### Automation / Scraping
- Axios
- Cheerio
- Google Search API
- OpenAI API (LLM)

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ controllers/
â”‚ â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ services/
â”‚ â””â”€â”€ server.js
â”‚
â”œâ”€â”€ automation/
â”‚ â”œâ”€â”€ index.js
â”‚ â”œâ”€â”€ googleSearch.js
â”‚ â”œâ”€â”€ scrapeArticle.js
â”‚ â””â”€â”€ rewriteWithLLM.js
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ src/
â”‚
â””â”€â”€ README.md


---

## ğŸ—„ï¸ Database Design

### Original Article
```json
{
  "title": "Article Title",
  "content": "Scraped content",
  "isOriginal": true,
  "isUpdated": false
}
```

---

## ğŸ—„ï¸ Database Design

### Original Article
```json
{
  "title": "Article Title",
  "content": "Scraped content",
  "isOriginal": true,
  "isUpdated": false
}
```

### AI-Updated Arcticle
```json
{
  "title": "Article Title",
  "content": "AI-enhanced content",
  "references": ["external_link_1", "external_link_2"],
  "isOriginal": false,
  "isUpdated": true,
  "originalArticleId": "ObjectId"
}
```

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Backend
```bash
cd backend
npm install
npm start
```

### 2ï¸âƒ£ Scrape Original Articles
```bash
curl -X POST http://localhost:5000/api/articles/scrape
```

### 3ï¸âƒ£ Run Automation
```bash
cd automation
node index.js
```

### 4ï¸âƒ£ Frontend
```bash
cd frontend
npm install
npm start
```

### ğŸ” Environment Variables
Create .env files locally (not committed).

Backend .env
```bash
MONGO_URI=mongodb://127.0.0.1:27017/beyondchats
PORT=5000
```

Automation .env
```bash
API_BASE_URL=http://localhost:5000/api/articles
OPENAI_API_KEY=your_openai_key
SERP_API_KEY=your_google_search_key
```



